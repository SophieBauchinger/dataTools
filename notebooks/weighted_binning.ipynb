{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1468c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import toolpac.calc.binprocessor as bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326b349",
   "metadata": {},
   "source": [
    "### Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f173c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = 50\n",
    "x1 = np.linspace(0,10,N1)\n",
    "y1 = x1 + 5*np.random.rand(N1)\n",
    "\n",
    "N2 = 15\n",
    "x2 = np.linspace(0,10,N2)\n",
    "y2 = x2 + 5*np.random.rand(N2)\n",
    "\n",
    "\n",
    "weights = [] # depends on bin_edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bec537",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [0,7.5,15]\n",
    "bci1d = bp.Bin_notequi1d(bin_edges)\n",
    "\n",
    "binned1 = bp.Simple_bin_1d(x1,y1, bci1d)\n",
    "binned2 = bp.Simple_bin_1d(x2,y2, bci1d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x1,y1)\n",
    "ax.scatter(x2,y2)\n",
    "\n",
    "for x in bin_edges:\n",
    "    ax.hlines(x,0,10, ls='dotted', color='lightgrey', zorder=0)\n",
    "\n",
    "for (mean, ylims) in zip(binned1.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:blue')\n",
    "\n",
    "for (mean, ylims) in zip(binned2.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_weights1 = [1/i for i in binned1.vcount]\n",
    "bin_weights2 = [1/i for i in binned2.vcount]\n",
    "bin_weights1, bin_weights2\n",
    "\n",
    "weight_per_point = [np.array([1/i]*int(i)) for i in binned1.vcount]\n",
    "weight_per_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin_i in [0,1]:\n",
    "    print(binned1.vbindata[bin_i], sum(binned1.vbindata[bin_i]*weight_per_point[bin_i]), binned1.vmean[bin_i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35779554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bin i\n",
    "bin_i = 0\n",
    "\n",
    "v_A = binned1.vbindata[bin_i]\n",
    "v_B = binned2.vbindata[bin_i]\n",
    "\n",
    "N_A = binned1.vcount[bin_i]\n",
    "N_B = binned2.vcount[bin_i]\n",
    "\n",
    "(1/N_A * sum(v_A) + 1/N_B * sum(v_B)) / ( N_A/N_A + N_B/N_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d30392",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/N_A * sum(v_A) + 1/N_B * sum(v_B)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb33f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to generalise for more than 2 data arrays\n",
    "\n",
    "def sample_x_y(N): \n",
    "    x = np.linspace(0,10, N)\n",
    "    y = x + 5*np.random.rand(N)\n",
    "    return N, x, y\n",
    "\n",
    "param_list = []\n",
    "for N in [50,15,30,100]:\n",
    "    (N,x,y) = sample_x_y(N)\n",
    "    param_list.append((N,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753206bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_sum(param_list):\n",
    "    \"\"\" param_list: List of (N,x_arr,y_arr)\"\"\"\n",
    "    total_weight = len(param_list) # nr of ascents\n",
    "\n",
    "    weighted_sum_list = []\n",
    "    for (x_arr, y_arr) in param_list:\n",
    "        N = len(y_arr)\n",
    "        weighted_sum = sum(y_arr) * 1/N\n",
    "        weighted_sum_list.append(weighted_sum)\n",
    "\n",
    "    return sum(weighted_sum_list) / total_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [0,7.5,15]\n",
    "bci1d = bp.Bin_notequi1d(bin_edges)\n",
    "\n",
    "binned1 = bp.Simple_bin_1d(x1,y1, bci1d)\n",
    "binned2 = bp.Simple_bin_1d(x2,y2, bci1d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x1,y1)\n",
    "ax.scatter(x2,y2)\n",
    "\n",
    "for x in bin_edges:\n",
    "    ax.hlines(x,0,10, ls='dotted', color='lightgrey', zorder=0)\n",
    "\n",
    "for (mean, ylims) in zip(binned1.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:blue')\n",
    "\n",
    "for (mean, ylims) in zip(binned2.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9597ee4",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted and unweighted binning\n",
    "\n",
    "# Prepare binning\n",
    "bin_edges = [0,2.5,5,6.5, 8.5,10]\n",
    "\n",
    "LIST_N = [10,15,300,20]\n",
    "colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "\n",
    "bci1d = bp.Bin_notequi1d(bin_edges)\n",
    "\n",
    "\n",
    "\n",
    "# Example data: x-array and y-array\n",
    "def sample_x_v(N): \n",
    "    x = np.linspace(0,10, N)\n",
    "    v = x + 10*np.random.rand(N)\n",
    "    return x, v\n",
    "data_list = []\n",
    "for N in LIST_N:\n",
    "    (x,v) = sample_x_v(N)\n",
    "    data_list.append((x,v))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate non-weighted mean for each bin\n",
    "x_simple = np.concatenate([i[0] for i in data_list])\n",
    "v_simple = np.concatenate([i[1] for i in data_list])\n",
    "\n",
    "unweighted_binned = bp.Simple_bin_1d(v_simple, x_simple, bci1d)\n",
    "\n",
    "\n",
    "\n",
    "# Sort into bins on x\n",
    "binned_list = []\n",
    "for x_v_tuple in data_list:\n",
    "    x,v = x_v_tuple \n",
    "    binned = bp.Simple_bin_1d(v, x, bci1d)\n",
    "    binned_list.append(binned)\n",
    "\n",
    "# Now calculate weighted mean per bin\n",
    "vmean_per_bin = []\n",
    "for i in np.arange(bci1d.nx): # Bin index\n",
    "    weighted_sum_list = []\n",
    "    for j, binned in enumerate(binned_list): # Ascent index\n",
    "        v_arr = binned.vbindata[i]\n",
    "        weighted_sum = sum(v_arr) * 1/len(v_arr) # TODO: sum() does not work for single float\n",
    "        weighted_sum_list.append(weighted_sum)\n",
    "    \n",
    "    total_weight = len(weighted_sum_list)\n",
    "    weighted_sum = sum(weighted_sum_list) / total_weight\n",
    "    vmean_per_bin.append(weighted_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "for x in bin_edges:\n",
    "    ax.hlines(x,0,20, ls='dotted', color='lightgrey', zorder=0)\n",
    "\n",
    "for i in np.arange(bci1d.nx):\n",
    "    # show normal means\n",
    "    for j, binned in enumerate(binned_list):\n",
    "        ax.scatter(binned.vmean[i], binned.xintm[i], color=colors[j], s=60, marker='d', zorder=10, label = LIST_N[j] if i==0 else '')\n",
    "        ax.scatter(binned.vbindata[i], binned.xbindata[i], color=colors[j], s=15, edgecolor='None', alpha=0.6)\n",
    "    \n",
    "    # show weighted means\n",
    "    xlims = bci1d.xint[i], bci1d.xint[i]+bci1d.xbsize[i]\n",
    "    ax.vlines(vmean_per_bin[i], *xlims, color = 'k', ls='dashed', label ='x$_w$' if i==0 else '')\n",
    "    \n",
    "    # show non-weighted mean\n",
    "    ax.vlines(unweighted_binned.vmean[i], *xlims, color='tab:cyan', ls='dashed', label ='x' if i==0 else '')\n",
    "\n",
    "ax.legend(title='Mean / N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7737809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to calculate the weighted standard deviation - get data from above\n",
    "\n",
    "# HAVE: binned_list, bci1d\n",
    "\n",
    "# Now calculate weighted mean per bin\n",
    "# vmean_per_bin = []\n",
    "# for i in np.arange(bci1d.nx): # Bin index\n",
    "    \n",
    "i = 0\n",
    "\n",
    "weighted_sum_list = []\n",
    "total_vbindata = []\n",
    "weight_list = []\n",
    "\n",
    "for j, binned in enumerate(binned_list): # Ascent index\n",
    "    v_arr = binned.vbindata[i]\n",
    "    if str(v_arr)=='nan': continue\n",
    "    weight = 1/len(v_arr)\n",
    "    \n",
    "    weight_list.append([weight]*len(v_arr))\n",
    "\n",
    "    weighted_sum = sum(v_arr) * weight \n",
    "    weighted_sum_list.append(weighted_sum)\n",
    "    \n",
    "    total_vbindata += list(v_arr)\n",
    "\n",
    "total_weight = len(weighted_sum_list)\n",
    "weighted_mean = sum(weighted_sum_list) / total_weight\n",
    "\n",
    "# calculate the weighted standard deviation\n",
    "diff_squared = [(val-weighted_mean)**2 for val in total_vbindata]\n",
    "weighted_diffs = [weight*ds for weight, ds in zip(np.concatenate(weight_list), diff_squared)]\n",
    "weighted_var = (np.nansum(weighted_diffs) / total_weight)\n",
    "weighted_std = weighted_var**0.5\n",
    "    \n",
    "weighted_mean, weighted_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ee8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import toolpac.calc.binprocessor as bp\n",
    "\n",
    "# Creating a function for weighted binning\n",
    "def weighted_binning(data_list, binclassinstance): \n",
    "    \"\"\" Weighted binning where each separate item in data_list contributes an equal amount (= 1). \n",
    "    \n",
    "    data_list (list[(v,x)]): List containing tuples with (v,x) data arrays\n",
    "    binclassinstance (bp.Bin_(not)equi1d): one-dimensional binning structure\n",
    "    \n",
    "    Returns lists of weighted mean and weighted standard deviation.\n",
    "    \"\"\"\n",
    "    # Sort into bins on x\n",
    "    binned_list = []\n",
    "    for x_v_tuple in data_list:\n",
    "        x,v = x_v_tuple \n",
    "        binned = bp.Simple_bin_1d(v, x, binclassinstance)\n",
    "        binned_list.append(binned)\n",
    "\n",
    "    # Now calculate weighted mean and std per bin\n",
    "    weighted_mean_per_bin = []\n",
    "    weighted_std_per_bin = []\n",
    "    for i in np.arange(binclassinstance.nx): # Bin index\n",
    "        weighted_sum_list = []\n",
    "        total_vbindata = []\n",
    "        weight_list = []\n",
    "\n",
    "        for j, binned in enumerate(binned_list): # Ascent index\n",
    "            v_arr = binned.vbindata[i]\n",
    "            if str(v_arr)=='nan': continue\n",
    "            weight = 1/len(v_arr)\n",
    "\n",
    "            weighted_sum_ascent = np.nansum(v_arr) * 1/len(v_arr) \n",
    "            weighted_sum_list.append(weighted_sum_ascent)\n",
    "            \n",
    "            weight_list.append([weight]*len(v_arr))\n",
    "            total_vbindata += list(v_arr)\n",
    "\n",
    "        total_weight = len(weighted_sum_list)\n",
    "        weighted_mean = sum(weighted_sum_list) / total_weight\n",
    "\n",
    "        # calculate the weighted standard deviation\n",
    "        diff_squared = [(val-weighted_mean)**2 for val in total_vbindata]\n",
    "        weighted_diffs = [weight*ds for weight, ds in zip(np.concatenate(weight_list), diff_squared)]\n",
    "        weighted_var = (np.nansum(weighted_diffs) / total_weight)\n",
    "        weighted_std = weighted_var**0.5\n",
    "        \n",
    "        weighted_mean_per_bin.append(weighted_mean)\n",
    "        weighted_std_per_bin.append(weighted_std)\n",
    "\n",
    "    return weighted_mean_per_bin, weighted_std_per_bin\n",
    "\n",
    "\n",
    "# Example data\n",
    "def sample_x_v(N): \n",
    "    x = np.linspace(0,10, N)\n",
    "    v = x + 10*np.random.rand(N)\n",
    "    return x, v\n",
    "\n",
    "LIST_N = [2,15,300,20]\n",
    "data_list = []\n",
    "for N in LIST_N:\n",
    "    (x,v) = sample_x_v(N)\n",
    "    data_list.append((x,v))\n",
    "\n",
    "# Prepare binning\n",
    "bin_edges = [0,2.5,5,6.5, 8.5,10]\n",
    "bci1d = bp.Bin_notequi1d(bin_edges)\n",
    "\n",
    "mean, std = weighted_binning(data_list, bci1d)\n",
    "[(m,s) for m,s in zip(mean, std)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2595f2b",
   "metadata": {},
   "source": [
    "### Weighted binning for climatology creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23031f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataTools.data.BinnedData as bin_tools\n",
    "\n",
    "def monthly_climatology(GlobalObject, subs, vcoord):\n",
    "    \"\"\" Create monthly binned profiles of subs (give data for a latitude band)\n",
    "    \n",
    "    Parameters: \n",
    "        GlobalObject (GlobalData)\n",
    "        subs (dcts.Substance)\n",
    "        vcoord (dcts.Coordinate): Vertical coord. for profile\n",
    "        lat_bsize (float): Size of latitude bands (even)\n",
    "    \"\"\"    \n",
    "    bci = bin_tools.make_bci(vcoord)\n",
    "    \n",
    "    binned_monthly = {}\n",
    "    \n",
    "    for month in set(GlobalObject.df.index.month):\n",
    "        data_month = GlobalObject.sel_month(month)\n",
    "        \n",
    "        data_list = []\n",
    "        for flight_nr in data_month.flights:\n",
    "            data_flight = data_month.sel_flight(flight_nr)\n",
    "            \n",
    "            x = data_flight.get_var_data(vcoord)\n",
    "            v = data_flight.get_var_data(subs)\n",
    "            data_list.append((x,v))\n",
    "\n",
    "        binned_m = bin_tools.weighted_binning(data_list, bci)\n",
    "        binned_monthly[month] = binned_m\n",
    "    \n",
    "    # binned_monthly = bin_tools.monthly_binning(\n",
    "    #     GlobalObject.df, subs, vcoord)\n",
    "    \n",
    "    # for month, BinData in binned_monthly.items():\n",
    "        \n",
    "    #     profile = BinData.\n",
    "\n",
    "    # pd.DataFrame()\n",
    "\n",
    "    return binned_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15032a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataTools.data import DataCollection\n",
    "from dataTools.data import data_getter\n",
    "\n",
    "stn_dict, station_df = data_getter.load_ozone_sonde_data([\"205\", \"254\"])\n",
    "\n",
    "woudc_data = DataCollection(station_df, 'WOUDC')\n",
    "woudc_data.data.update(**stn_dict)\n",
    "\n",
    "# Define subs / coord\n",
    "[o3_subs] = woudc_data.get_substs(short_name='o3', model='MSMT', unit='ppb')\n",
    "[pt_coord] = woudc_data.get_coords(vcoord='pt', model='MSMT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80177f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "woudc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly_climatology(woudc_data, o3_subs, theta_coord)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
