{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1468c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import toolpac.calc.binprocessor_v2 as bp\n",
    "\n",
    "import dataTools.data.BinnedData as bin_tools\n",
    "from dataTools.data import DataCollection\n",
    "from dataTools.data import data_getter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326b349",
   "metadata": {},
   "source": [
    "### Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f173c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = 50\n",
    "x1 = np.linspace(0,10,N1)\n",
    "y1 = x1 + 5*np.random.rand(N1)\n",
    "\n",
    "N2 = 15\n",
    "x2 = np.linspace(0,10,N2)\n",
    "y2 = x2 + 5*np.random.rand(N2)\n",
    "\n",
    "\n",
    "weights = [] # depends on bin_edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bec537",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [0,7.5,15]\n",
    "bci1d = bp.Bin1D(xbinlimits = bin_edges)\n",
    "\n",
    "binned1 = bp.BinnedData1D(x1,y1, bci1d)\n",
    "binned2 = bp.BinnedData1D(x2,y2, bci1d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x1,y1)\n",
    "ax.scatter(x2,y2)\n",
    "\n",
    "for x in bin_edges:\n",
    "    ax.hlines(x,0,10, ls='dotted', color='lightgrey', zorder=0)\n",
    "\n",
    "for (mean, ylims) in zip(binned1.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:blue')\n",
    "\n",
    "for (mean, ylims) in zip(binned2.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_weights1 = [1/i for i in binned1.vcount]\n",
    "bin_weights2 = [1/i for i in binned2.vcount]\n",
    "bin_weights1, bin_weights2\n",
    "\n",
    "weight_per_point = [np.array([1/i]*int(i)) for i in binned1.vcount]\n",
    "weight_per_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin_i in [0,1]:\n",
    "    print(binned1.vbindata[bin_i], sum(binned1.vbindata[bin_i]*weight_per_point[bin_i]), binned1.vmean[bin_i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35779554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bin i\n",
    "bin_i = 0\n",
    "\n",
    "v_A = binned1.vbindata[bin_i]\n",
    "v_B = binned2.vbindata[bin_i]\n",
    "\n",
    "N_A = binned1.vcount[bin_i]\n",
    "N_B = binned2.vcount[bin_i]\n",
    "\n",
    "(1/N_A * sum(v_A) + 1/N_B * sum(v_B)) / ( N_A/N_A + N_B/N_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d30392",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/N_A * sum(v_A) + 1/N_B * sum(v_B)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb33f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to generalise for more than 2 data arrays\n",
    "\n",
    "def sample_x_y(N): \n",
    "    x = np.linspace(0,10, N)\n",
    "    y = x + 5*np.random.rand(N)\n",
    "    return N, x, y\n",
    "\n",
    "param_list = []\n",
    "for N in [50,15,30,100]:\n",
    "    (N,x,y) = sample_x_y(N)\n",
    "    param_list.append((N,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753206bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_sum(param_list):\n",
    "    \"\"\" param_list: List of (N,x_arr,y_arr)\"\"\"\n",
    "    total_weight = len(param_list) # nr of ascents\n",
    "\n",
    "    weighted_sum_list = []\n",
    "    for (x_arr, y_arr) in param_list:\n",
    "        N = len(y_arr)\n",
    "        weighted_sum = sum(y_arr) * 1/N\n",
    "        weighted_sum_list.append(weighted_sum)\n",
    "\n",
    "    return sum(weighted_sum_list) / total_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [0,7.5,15]\n",
    "bci1d = bp.Bin1D(xbinlimits=bin_edges)\n",
    "\n",
    "binned1 = bp.BinnedData1D(x1,y1, bci1d)\n",
    "binned2 = bp.BinnedData1D(x2,y2, bci1d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x1,y1)\n",
    "ax.scatter(x2,y2)\n",
    "\n",
    "for x in bin_edges:\n",
    "    ax.hlines(x,0,10, ls='dotted', color='lightgrey', zorder=0)\n",
    "\n",
    "for (mean, ylims) in zip(binned1.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:blue')\n",
    "\n",
    "for (mean, ylims) in zip(binned2.vmean, ([0,7.5], [7.5,15])):\n",
    "    ax.vlines(mean, *ylims, ls='dashed', color='tab:orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9597ee4",
   "metadata": {},
   "source": [
    "### Implementation - random example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted and unweighted binning\n",
    "\n",
    "# Prepare binning\n",
    "bin_edges = [0,2.5,5,6.5, 8.5,10]\n",
    "\n",
    "LIST_N = [20,70,400]\n",
    "colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "\n",
    "bci1d = bp.Bin1D(xbinlimits = bin_edges)\n",
    "\n",
    "# Example data: x-array and y-array\n",
    "def sample_x_v(N): \n",
    "    x = np.linspace(0,10, N)\n",
    "    v = x**0.8 + 2*np.random.rand(N) + 0.3*N**0.5\n",
    "    return x, v\n",
    "data_list = []\n",
    "for N in LIST_N:\n",
    "    (x,v) = sample_x_v(N)\n",
    "    data_list.append((x,v))\n",
    "\n",
    "# Calculate non-weighted mean for each bin\n",
    "x_simple = np.concatenate([i[0] for i in data_list])\n",
    "v_simple = np.concatenate([i[1] for i in data_list])\n",
    "\n",
    "unweighted_binned = bp.BinnedData1D(v_simple, x_simple, bci1d)\n",
    "\n",
    "# Sort into bins on x\n",
    "binned_list = []\n",
    "for x_v_tuple in data_list:\n",
    "    x,v = x_v_tuple \n",
    "    binned = bp.BinnedData1D(v, x, bci1d)\n",
    "    binned_list.append(binned)\n",
    "\n",
    "# Now calculate weighted mean per bin\n",
    "vmean_per_bin = []\n",
    "for i in np.arange(bci1d.nx): # Bin index\n",
    "    weighted_sum_list = []\n",
    "    for j, binned in enumerate(binned_list): # Ascent index\n",
    "        v_arr = binned.vbindata[i]\n",
    "        if str(v_arr)=='nan': continue\n",
    "        weight = 1/len(v_arr)\n",
    "        weighted_sum = sum(v_arr) * weight\n",
    "        weighted_sum_list.append(weighted_sum)\n",
    "    \n",
    "    total_weight = len(weighted_sum_list)\n",
    "    weighted_sum = sum(weighted_sum_list) / total_weight\n",
    "    vmean_per_bin.append(weighted_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "for x in bin_edges:\n",
    "    ax.hlines(x,0,20, ls='dotted', color='lightgrey', zorder=0)\n",
    "\n",
    "for i in np.arange(bci1d.nx):\n",
    "    # show normal means\n",
    "    for j, binned in enumerate(binned_list):\n",
    "        ax.scatter(binned.vmean[i], binned.xintm[i], \n",
    "                   color=colors[j], s=60, marker='d', \n",
    "                   zorder=10, label = LIST_N[j] if i==0 else '',\n",
    "                   edgecolor='k', lw=0.7)\n",
    "        ax.scatter(binned.vbindata[i], binned.xbindata[i], \n",
    "                   color=colors[j], s=15, edgecolor='None', alpha=0.6)\n",
    "    \n",
    "    # show weighted means\n",
    "    xlims = bci1d.xint[i], bci1d.xint[i]+bci1d.xbsize[i]\n",
    "    ax.vlines(vmean_per_bin[i], *xlims, \n",
    "              color = 'k', lw=2,\n",
    "              label ='x$_w$' if i==0 else '')\n",
    "    \n",
    "    # show non-weighted mean\n",
    "    ax.vlines(unweighted_binned.vmean[i], *xlims, \n",
    "              color='tab:red',lw=2,\n",
    "              label ='x' if i==0 else '')\n",
    "\n",
    "ax.legend(title='Mean / N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7737809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to calculate the weighted standard deviation - get data from above\n",
    "\n",
    "# HAVE: binned_list, bci1d\n",
    "\n",
    "# Now calculate weighted mean per bin\n",
    "# vmean_per_bin = []\n",
    "# for i in np.arange(bci1d.nx): # Bin index\n",
    "    \n",
    "i = 0\n",
    "\n",
    "weighted_sum_list = []\n",
    "total_vbindata = []\n",
    "weight_list = []\n",
    "\n",
    "for j, binned in enumerate(binned_list): # Ascent index\n",
    "    v_arr = binned.vbindata[i]\n",
    "    if str(v_arr)=='nan': continue\n",
    "    weight = 1/len(v_arr)\n",
    "    \n",
    "    weight_list.append([weight]*len(v_arr))\n",
    "\n",
    "    weighted_sum = sum(v_arr) * weight \n",
    "    weighted_sum_list.append(weighted_sum)\n",
    "    \n",
    "    total_vbindata += list(v_arr)\n",
    "\n",
    "total_weight = len(weighted_sum_list)\n",
    "weighted_mean = sum(weighted_sum_list) / total_weight\n",
    "\n",
    "# calculate the weighted standard deviation\n",
    "diff_squared = [(val-weighted_mean)**2 for val in total_vbindata]\n",
    "weighted_diffs = [weight*ds for weight, ds in zip(np.concatenate(weight_list), diff_squared)]\n",
    "weighted_var = (np.nansum(weighted_diffs) / total_weight)\n",
    "weighted_std = weighted_var**0.5\n",
    "    \n",
    "weighted_mean, weighted_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ee8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import toolpac.calc.binprocessor_v2 as bp\n",
    "\n",
    "# Creating a function for weighted binning\n",
    "def weighted_binning(data_list, binclassinstance): \n",
    "    \"\"\" Weighted binning where each separate item in data_list contributes an equal amount (= 1). \n",
    "    \n",
    "    data_list (list[(v,x)]): List containing tuples with (v,x) data arrays\n",
    "    binclassinstance (bp.Bin_(not)equi1d): one-dimensional binning structure\n",
    "    \n",
    "    Returns lists of weighted mean and weighted standard deviation.\n",
    "    \"\"\"\n",
    "    # Sort into bins on x\n",
    "    binned_list = []\n",
    "    for x_v_tuple in data_list:\n",
    "        x,v = x_v_tuple \n",
    "        binned = bp.BinnedData1D(v, x, binclassinstance)\n",
    "        binned_list.append(binned)\n",
    "\n",
    "    # Now calculate weighted mean and std per bin\n",
    "    weighted_mean_per_bin = []\n",
    "    weighted_std_per_bin = []\n",
    "    for i in np.arange(binclassinstance.nx): # Bin index\n",
    "        weighted_sum_list = []\n",
    "        total_vbindata = []\n",
    "        weight_list = []\n",
    "\n",
    "        for j, binned in enumerate(binned_list): # Ascent index\n",
    "            try: v_arr = binned.vbindata[i]\n",
    "            except: print('vbd', binned.vbindata); continue\n",
    "            if str(v_arr)=='nan': continue\n",
    "            weight = 1/len(v_arr)\n",
    "\n",
    "            weighted_sum_ascent = np.nansum(v_arr) * 1/len(v_arr) \n",
    "            weighted_sum_list.append(weighted_sum_ascent)\n",
    "            \n",
    "            weight_list.append([weight]*len(v_arr))\n",
    "            total_vbindata += list(v_arr)\n",
    "\n",
    "        total_weight = len(weighted_sum_list)\n",
    "        weighted_mean = sum(weighted_sum_list) / total_weight\n",
    "\n",
    "        # calculate the weighted standard deviation\n",
    "        diff_squared = [(val-weighted_mean)**2 for val in total_vbindata]\n",
    "        weighted_diffs = [weight*ds for weight, ds in zip(np.concatenate(weight_list), diff_squared)]\n",
    "        weighted_var = (np.nansum(weighted_diffs) / total_weight)\n",
    "        weighted_std = weighted_var**0.5\n",
    "        \n",
    "        weighted_mean_per_bin.append(weighted_mean)\n",
    "        weighted_std_per_bin.append(weighted_std)\n",
    "\n",
    "    return weighted_mean_per_bin, weighted_std_per_bin\n",
    "\n",
    "\n",
    "# Example data\n",
    "def sample_x_v(N): \n",
    "    x = np.linspace(0,10, N)\n",
    "    v = x + 10*np.random.rand(N)\n",
    "    return x, v\n",
    "\n",
    "LIST_N = [2,15,300,20]\n",
    "data_list = []\n",
    "for N in LIST_N:\n",
    "    (x,v) = sample_x_v(N)\n",
    "    data_list.append((x,v))\n",
    "\n",
    "# Prepare binning\n",
    "bin_edges = [0,2.5,5,6.5, 8.5,10]\n",
    "bci1d = bp.Bin1D(xbinlimits=bin_edges)\n",
    "\n",
    "mean, std = weighted_binning(data_list, bci1d)\n",
    "[(m,s) for m,s in zip(mean, std)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2595f2b",
   "metadata": {},
   "source": [
    "### Weighted binning for climatology creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23031f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_climatology(GlobalObject, subs, vcoord, bin_kwargs):\n",
    "    \"\"\" Create monthly binned profiles of subs (give data for a latitude band)\n",
    "    \n",
    "    Parameters: \n",
    "        GlobalObject (GlobalData)\n",
    "        subs (dcts.Substance)\n",
    "        vcoord (dcts.Coordinate): Vertical coord. for profile\n",
    "        lat_bsize (float): Size of latitude bands (even)\n",
    "    \"\"\"    \n",
    "    bci = bin_tools.make_bci(vcoord, **bin_kwargs)\n",
    "\n",
    "    binned_monthly = {}\n",
    "\n",
    "    for month in set(GlobalObject.df.index.month):\n",
    "        data_month = GlobalObject.sel_month(month)\n",
    "\n",
    "        data_list = []\n",
    "        for flight_nr in data_month.flights:\n",
    "            data_flight = data_month.sel_flight(flight_nr)\n",
    "            \n",
    "            x = data_flight.get_var_data(vcoord)\n",
    "            v = data_flight.get_var_data(subs)\n",
    "            data_list.append((x,v))\n",
    "\n",
    "        mean, std = bin_tools.weighted_binning(data_list, bci)\n",
    "        binned_monthly[month] = (mean, std)\n",
    "\n",
    "    return binned_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15032a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload; reload(data_getter)\n",
    "pdir = r\"C:\\Users\\sophie_bauchinger\\Documents\\GitHub\\chemTPanalyses\\chemTPanalyses\\data\\store\"\n",
    "stn_dict, station_df = data_getter.load_ozone_sonde_data([\"205\", \"254\"], pdir=pdir)\n",
    "\n",
    "woudc_data = DataCollection(station_df, 'WOUDC')\n",
    "woudc_data.data.update(**stn_dict)\n",
    "\n",
    "# Define subs / coord\n",
    "[o3_subs] = woudc_data.get_substs(short_name='o3', model='MSMT', unit='ppb')\n",
    "[pt_coord] = woudc_data.get_coords(vcoord='pt', model='MSMT')\n",
    "\n",
    "# monthly_climatology(woudc_data, o3_subs, pt_coord, {'xbmax':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35972923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload; reload(bin_tools)\n",
    "GlobalObject = woudc_data\n",
    "subs = o3_subs\n",
    "vcoord = pt_coord\n",
    "\n",
    "bci = bin_tools.make_bci(vcoord, xbmax=1000)\n",
    "# bci = bin_tools.make_bci(vcoord)\n",
    "\n",
    "binned_monthly = {}\n",
    "\n",
    "for month in set(GlobalObject.df.index.month):\n",
    "    data_month = GlobalObject.sel_month(month)\n",
    "\n",
    "    data_list = []\n",
    "    for flight_nr in data_month.flights:\n",
    "        data_flight = data_month.sel_flight(flight_nr)\n",
    "        \n",
    "        x = data_flight.get_var_data(vcoord)\n",
    "        v = data_flight.get_var_data(subs)\n",
    "        data_list.append((x,v))\n",
    "\n",
    "    mean, std = bin_tools.weighted_binning(data_list, bci)\n",
    "    binned_monthly[month] = (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataTools.dictionaries as dcts\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(5,8))\n",
    "\n",
    "for month, (w_mean, std) in binned_monthly.items():\n",
    "    ax.plot(w_mean, bci.xintm, color = dcts.dict_month()[f\"color_{month}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin([np.nanmin(i[0]) for i in binned_monthly.values()]),\n",
    "np.nanmax([np.nanmax(i[0]) for i in binned_monthly.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bci.xintm[0]-50*bci.xbsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841feabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataTools.plot.create_figure as cfig; reload(cfig)\n",
    "fig, axs = plt.subplots(3,4, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "axs.flat[0].set_ylim(bci.xintm[0]-bci.xbsize, bci.xintm[-1]+bci.xbsize)\n",
    "axs.flat[0].set_xlim(\n",
    "    np.nanmin([np.nanmin(i[0]) for i in binned_monthly.values()]) - 400,\n",
    "    np.nanmax([np.nanmax(i[0]) for i in binned_monthly.values()]))\n",
    "for (month, (w_mean, std)), ax in zip(binned_monthly.items(), axs.flat):\n",
    "    ax.scatter(\n",
    "        GlobalObject.sel_month(month).get_var_data(subs),\n",
    "        GlobalObject.sel_month(month).get_var_data(vcoord),\n",
    "        alpha = 0.2, edgecolor=\"None\", color = dcts.dict_month()[f\"color_{month}\"])\n",
    "    ax.plot(w_mean, bci.xintm, color = 'k', path_effects = [cfig.outline(lw=2)], lw=2)\n",
    "\n",
    "for ax in axs[-1,:]:\n",
    "    ax.set_xlabel(subs.label())\n",
    "for ax in axs[:,0]: \n",
    "    ax.set_ylabel(vcoord.label())\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle(\"WOUDC climatology for normalised ozone sonde msmts at stations 205 and 245\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb441556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataTools.plot.create_figure as cfig; reload(cfig)\n",
    "fig, axs = plt.subplots(3,4, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "axs.flat[0].set_ylim(bci.xintm[0]-bci.xbsize, 600)\n",
    "axs.flat[0].set_xlim(\n",
    "    np.nanmin([np.nanmin(i[0]) for i in binned_monthly.values()])-500, 7000)\n",
    "for (month, (w_mean, std)), ax in zip(binned_monthly.items(), axs.flat):\n",
    "    ax.scatter(\n",
    "        GlobalObject.sel_month(month).get_var_data(subs),\n",
    "        GlobalObject.sel_month(month).get_var_data(vcoord),\n",
    "        alpha = 0.2, edgecolor=\"None\", color = dcts.dict_month()[f\"color_{month}\"])\n",
    "    ax.scatter(w_mean, bci.xintm, color = 'k', path_effects = [cfig.outline(lw=2)], lw=2)\n",
    "\n",
    "for ax in axs[-1,:]:\n",
    "    ax.set_xlabel(subs.label())\n",
    "for ax in axs[:,0]: \n",
    "    ax.set_ylabel(vcoord.label())\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle(\"WOUDC climatology for normalised ozone sonde msmts at stations 205 and 245\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df8fbf",
   "metadata": {},
   "source": [
    "### Weighted binning class (1D and 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_weighted_clim(GlobalObject, subs, vcoord, bin_kwargs):\n",
    "    \"\"\" Create monthly binned profiles of subs (give data for a latitude band)\n",
    "    \n",
    "    Parameters: \n",
    "        GlobalObject (GlobalData)\n",
    "        subs (dcts.Substance)\n",
    "        vcoord (dcts.Coordinate): Vertical coord. for profile\n",
    "        lat_bsize (float): Size of latitude bands (even)\n",
    "    \"\"\"    \n",
    "    bci = bin_tools.make_bci(vcoord, **bin_kwargs)\n",
    "\n",
    "    binned_monthly = {}\n",
    "\n",
    "    for month in set(GlobalObject.df.index.month):\n",
    "        data_month = GlobalObject.sel_month(month)\n",
    "\n",
    "        data_list = []\n",
    "        for flight_nr in data_month.flights:\n",
    "            data_flight = data_month.sel_flight(flight_nr)\n",
    "            \n",
    "            x = data_flight.get_var_data(vcoord)\n",
    "            v = data_flight.get_var_data(subs)\n",
    "            data_list.append((v,x))\n",
    "\n",
    "        binned = bp.WeightedBinning1D(data_list, bci)\n",
    "        mean, std = binned.weighted_mean, binned.weighted_std\n",
    "        binned_monthly[month] = (mean, std)\n",
    "\n",
    "    return binned_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload; reload(data_getter)\n",
    "pdir = r\"C:\\Users\\sophie_bauchinger\\Documents\\GitHub\\chemTPanalyses\\chemTPanalyses\\data\\store\"\n",
    "stn_dict, station_df,_ = data_getter.load_ozone_sonde_data([\"205\", \"254\"], pdir=pdir)\n",
    "\n",
    "woudc_data = DataCollection(station_df, 'WOUDC')\n",
    "woudc_data.data.update(**stn_dict)\n",
    "\n",
    "# Define subs / coord\n",
    "[o3_subs] = woudc_data.get_substs(short_name='o3', model='MSMT', unit='ppb')\n",
    "[pt_coord] = woudc_data.get_coords(vcoord='pt', model='MSMT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6cd0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dataTools.dictionaries as dcts\n",
    "\n",
    "binned_monthly = monthly_weighted_clim(\n",
    "    woudc_data, o3_subs, pt_coord, {'xbmax':1000})\n",
    "bci = bin_tools.make_bci(pt_coord, xbmax=1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,8))\n",
    "for month, (w_mean, std) in binned_monthly.items():\n",
    "    ax.plot(w_mean, bci.xintm, color = dcts.dict_month()[f\"color_{month}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataTools.plot.create_figure as cfig; reload(cfig)\n",
    "fig, axs = plt.subplots(3,4, sharex=True, sharey=True, figsize=(8,8))\n",
    "\n",
    "axs.flat[0].set_ylim(bci.xintm[0]-bci.xbsize, bci.xintm[-1]+bci.xbsize)\n",
    "axs.flat[0].set_xlim(\n",
    "    np.nanmin([np.nanmin(i[0]) for i in binned_monthly.values()]) - 400,\n",
    "    np.nanmax([np.nanmax(i[0]) for i in binned_monthly.values()]))\n",
    "for (month, (w_mean, std)), ax in zip(binned_monthly.items(), axs.flat):\n",
    "    ax.scatter(\n",
    "        woudc_data.sel_month(month).get_var_data(o3_subs),\n",
    "        woudc_data.sel_month(month).get_var_data(pt_coord),\n",
    "        alpha = 0.2, edgecolor=\"None\", color = dcts.dict_month()[f\"color_{month}\"])\n",
    "    ax.plot(w_mean, bci.xintm, color = 'k', path_effects = [cfig.outline(lw=2)], lw=2)\n",
    "\n",
    "for ax in axs[-1,:]:\n",
    "    ax.set_xlabel(o3_subs.label())\n",
    "for ax in axs[:,0]: \n",
    "    ax.set_ylabel(pt_coord.label())\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle(\"WOUDC climatology for normalised ozone sonde msmts at stations 205 and 245\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
